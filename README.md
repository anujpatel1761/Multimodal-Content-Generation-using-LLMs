#  Multimodal Content Generation using LLMs and Vision Models

A full-stack multimodal AI application that combines **Natural Language Processing (NLP)**, **Computer Vision**, and **Text-to-Image Generation**. This project allows users to chat with an AI assistant, summarize images, and generate visuals from text using **Google Gemini** and **Stable Diffusion XL** via **Replicate API**.

---

## ðŸ”‘ Features

- **ðŸ—£ï¸ Chat + Image Understanding**  
  Upload an image and interact with it via a conversational interface using **Gemini Pro Vision** + **Gemini 1.5 Pro**.

- **ðŸŽ¨ Text-to-Image Generation**  
  Create custom visuals by describing them in natural language. Powered by **Stable Diffusion XL** via Replicate.

- **âš™ï¸ Configurable Parameters**  
  Tune image generation settings like resolution, denoising steps, prompt strength, and schedulers.

- **ðŸ–¼ï¸ Real-Time Streaming & UI**  
  Stream assistant responses token by token with **Streamlit**. Includes image upload, progress states, and memory.

---

## ðŸ› ï¸ Tech Stack

| Category        | Tools |
|----------------|-------|
| ðŸ”® LLM & Vision | Google Gemini (`gemini-1.5-pro-latest`, `gemini-1.5-flash`) |
| ðŸŽ¨ Image Gen    | Stable Diffusion XL via [Replicate](https://replicate.com/) |
| ðŸŒ Frontend     | Streamlit |
| ðŸ–¼ï¸ Image Proc   | Pillow (PIL) |
| ðŸ” Secrets      | python-dotenv |
| ðŸ“¦ Env Mgmt     | Conda / pip |

---

## ðŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/anujpatel1761/Multimodal-Content-Generation-using-LLMs.git
cd Multimodal-Content-Generation-using-LLMs
```

### 2. Set Up Environment for project

```bash
conda create -n multimodal-ai python=3.10
conda activate multimodal-ai
pip install -r requirements.txt
```

### 3. Configure API Keys

Create a `.env` file in the root folder:

```env
GOOGLE_API_KEY=google_api_key_here
REPLICATE_API_TOKEN=replicate_token_here
```

---

## â–¶ï¸ Run the App

```bash
streamlit run multi-modal-content-generation.py
```

Open the app at: `http://localhost:8501`

---

## ðŸ–¼ï¸ UI Preview

> ðŸ“· Screenshot of Text-to-Image Generation Mode:

![UI Screenshot](UIUX.png)

---

## ðŸ§ª Example Prompts

- **Text-to-Image:**  
  `Give me an image of a person writing code.`

- **Chat + Vision:**  
  Upload an image and ask:  
  `Describe what's happening in this image.`

---

## ðŸ’¡ Future Enhancements

- Replace deprecated Gemini Vision model with `gemini-1.5-flash`
- Add multi-image upload support
- Improve image streaming performance

---



## ðŸ™Œ Acknowledgments

- [Google Generative AI](https://ai.google.dev/)
- [Replicate](https://replicate.com/)
- [Streamlit](https://streamlit.io/)
